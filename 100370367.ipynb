{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6384fdf",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4a57127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "pd.set_option('max_rows', 10)\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fbc02",
   "metadata": {},
   "source": [
    "Parse in the banzuke (rankings) by decade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b8efbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the ranking dataframes by decade\n",
    "ranking_1950 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_1960 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_1970 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_1980 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_1990 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_2000 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_2010 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "ranking_2020 = pd.DataFrame([],columns=(\"rank_code\", \"name\", \"birthplace\", \"stable\", \"dob\", \"height\", \"weight\", \"rank_no\", \"rank_date\", \"division\", \"age\")) \n",
    "\n",
    "def parse_ranking_data(path, df):\n",
    "\n",
    "    #set the path to the ranking files\n",
    "    ranking_file_path = os.chdir(path)\n",
    "\n",
    "    #loop through each file in the decade folder\n",
    "    for files in os.listdir(ranking_file_path):           \n",
    "                    \n",
    "        file_name = files\n",
    "        files = open(file_name, \"r\")\n",
    "        lines = files.readlines()\n",
    "        files.close()\n",
    "\n",
    "        #reset rank after each file is read\n",
    "        rank_no = 0\n",
    "\n",
    "        #get the date of the sumo ranking\n",
    "        rank_date_string = file_name[0:4] + \"-\" + file_name[5:7]\n",
    "        rank_date = datetime.datetime.strptime(rank_date_string, \"%Y-%m\")\n",
    "\n",
    "        #parse in the data by looping through each line in the file\n",
    "        for line in lines:\n",
    "\n",
    "            #use the number of spaces in the line and the beginning of the rank codes to filter out the irrelevant lines                    \n",
    "            if \"    \" in line and \"changed from\" not in line and line.startswith(\"Bg\") == False and line.startswith(\"Sj\") == False and line.startswith(\"Mz\") == False:\n",
    "                line = line + \" \"\n",
    "\n",
    "                #remove extra spaces\n",
    "                processed_line = re.sub(' +', ' ', line)\n",
    "\n",
    "                #separates the columns \n",
    "                split = processed_line.split(\" \")\n",
    "                \n",
    "                #splits the rank from the name if the longer names merged\n",
    "                if len(split[0]) >= 7:\n",
    "                    split[6] = split[5]\n",
    "                    split[5] = split[4]\n",
    "                    split[4] = split[3]\n",
    "                    split[3] = split[2]\n",
    "                    split[2] = split[1]\n",
    "                    split[1] = split[0][7:]\n",
    "                    split[0] = split[0][:7]\n",
    "                    \n",
    "                #splits the name from the birthplace if the strings merged\n",
    "                if len(split[1]) >= 15:\n",
    "                    charCount = 0\n",
    "                    upperCount = 0\n",
    "\n",
    "                    for char in split[1]:\n",
    "                        charCount +=1\n",
    "\n",
    "                        if char == char.upper():\n",
    "                            upperCount += 1\n",
    "\n",
    "                            if upperCount == 2:\n",
    "                                split[6] = split[5]\n",
    "                                split[5] = split[4]\n",
    "                                split[4] = split[3]\n",
    "                                split[3] = split[2]\n",
    "                                split[2] = split[1][charCount:]\n",
    "                                split[1] = split[1][:charCount] \n",
    "\n",
    "                #splits the birthplace and the stable if they have merged\n",
    "                if len(split[2]) >= 12:\n",
    "                    charCount = 0\n",
    "                    upperCount = 0\n",
    "\n",
    "                    for char in split[2]:\n",
    "                        charCount +=1\n",
    "\n",
    "                        if char == char.upper():\n",
    "                            upperCount += 1\n",
    "\n",
    "                            if upperCount == 2:\n",
    "                                split[6] = split[5]\n",
    "                                split[5] = split[4]\n",
    "                                split[4] = split[3]\n",
    "                                split[3] = split[2][charCount-1:]\n",
    "                                split[2] = split[2][:charCount-1]\n",
    "\n",
    "                #corrects the split if birthplace is Hong Kong or Sri Lanka\n",
    "                if split[2] == \"Hong\" and split[3][:4] == \"Kong\":\n",
    "                    split[3] = split[4]\n",
    "                    split[4] = split[5]\n",
    "                    split[5] = split[6]\n",
    "                    split[6] = split[7]                      \n",
    "                    split[2] = \"Hong Kong\" \n",
    "\n",
    "                elif split[2] == \"Sri\" and split[3][:4] == \"Lank\":\n",
    "                    split[3] = split[4]\n",
    "                    split[4] = split[5]\n",
    "                    split[5] = split[6]\n",
    "                    split[6] = split[7]                      \n",
    "                    split[2] = \"Sri Lanka\" \n",
    "\n",
    "                #splits the birthplace from the stable if the birthplace has a space\n",
    "                if len(split[3]) >= 6:\n",
    "                    charCount = 0\n",
    "                    upperCount = 0\n",
    "\n",
    "                    for char in split[3]:\n",
    "                        charCount +=1\n",
    "\n",
    "                        if char == char.upper():\n",
    "                            upperCount += 1\n",
    "\n",
    "                            if upperCount == 2: \n",
    "                                split[2] = split[2] + \" \" + split[3][:charCount-1].title()\n",
    "                                split[3] = split[3][charCount-1:]\n",
    "\n",
    "                #default column layout\n",
    "                rank_code = split[0]\n",
    "                name = split[1]\n",
    "                birthplace = split[2]\n",
    "                stable = split[3]\n",
    "                dob = split[4]\n",
    "                height = split[5]\n",
    "                weight = split[6]\n",
    "                rank_no = rank_no + 1\n",
    "\n",
    "                #convert height to int\n",
    "                if height[0] == \"-\":\n",
    "                    height = \"-\"\n",
    "                else: \n",
    "                    height = float(height)\n",
    "\n",
    "                #convert height to int\n",
    "                if weight[0] == \"-\":\n",
    "                    weight = \"-\"\n",
    "                else: \n",
    "                    weight = float(weight)\n",
    "\n",
    "                #convert dob to date\n",
    "                if dob[0] == \"-\":\n",
    "                    dob = \"-\"\n",
    "                else:\n",
    "                    dob = dob[6:11] + \"-\" + dob[3:5] + \"-\" +  dob[0:2]\n",
    "                    dob = datetime.datetime.strptime(dob, \"%Y-%m-%d\")\n",
    "\n",
    "                #calculate age if dob is given\n",
    "                if dob == \"-\":\n",
    "                    age = \"-\"\n",
    "                else:\n",
    "                    age = rank_date - dob\n",
    "                \n",
    "                #set division\n",
    "                if rank_code[0].upper() == \"Y\" or rank_code[0].upper() == \"O\" or rank_code[0].upper() == \"K\":\n",
    "                    division = \"Makuuchi\"\n",
    "                elif rank_code[0].upper() == \"S\":\n",
    "                    if rank_code[1].upper() == \"D\":\n",
    "                        division = \"Sandanme\"\n",
    "                    else:\n",
    "                        division = \"Makuuchi\"\n",
    "                elif rank_code[0].upper() == \"M\":\n",
    "                    if rank_code[1].upper() == \"S\":\n",
    "                        division = \"Makushita\"\n",
    "                    else:\n",
    "                        division = \"Makuuchi\"\n",
    "                elif rank_code[0].upper() == \"J\":\n",
    "                    if rank_code[1].upper() == \"D\":\n",
    "                        division = \"Jonidan\"\n",
    "                    elif rank_code[1].upper() == \"K\":\n",
    "                        division = \"Jonokuchi\"\n",
    "                    else:\n",
    "                        division = \"Juryo\"\n",
    "\n",
    "                #apply the data to the dataframe\n",
    "                df.loc[len(df.index)] = [rank_code, name, birthplace, stable, dob, height, weight, rank_no, rank_date, division, age]\n",
    "                \n",
    "#parse the data for each decade\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1950/\", ranking_1950)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1960/\", ranking_1960)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1970/\", ranking_1970)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1980/\", ranking_1980)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1990/\", ranking_1990)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/2000/\", ranking_2000)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/2010/\", ranking_2010)\n",
    "parse_ranking_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/2020/\", ranking_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41444d28",
   "metadata": {},
   "source": [
    "Delete the \"day 16\" files from the tournament folder as they do not provide bout insights. Then, parse in each tournament file by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "081bcb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the tournament dataframes by decade\n",
    "tournament_1950 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_1960 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_1970 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_1980 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_1990 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_2000 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_2010 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "tournament_2020 = pd.DataFrame(columns=(\"date\", \"day_no\", \"division\", \"win_technique\",\"rank_1\", \"name_1\", \"record_1\", \"rank_2\", \"name_2\", \"record_2\"))\n",
    "\n",
    "def parse_tournament_data(path, df):    \n",
    "    #set the path to the tournament file\n",
    "    tournament_file_path = os.chdir(path)\n",
    "\n",
    "    #loop through each file in the decade folder\n",
    "    for files in os.listdir(tournament_file_path):    \n",
    "\n",
    "        file_name = files\n",
    "        files = open(file_name, \"r\")\n",
    "        lines = files.readlines()\n",
    "        files.close()\n",
    "\n",
    "        #get date of the tournament\n",
    "        tournament_date_string = file_name[0:4] + \"-\" + file_name[5:7]\n",
    "        tournament_date = datetime.datetime.strptime(tournament_date_string, \"%Y-%m\")\n",
    "\n",
    "        #get the day of the tournament\n",
    "        tournament_day_no = int(file_name[-6:-4])\n",
    "\n",
    "        #parse in the data by looping through each line in the file\n",
    "        for line in lines:\n",
    "\n",
    "            #get the division of the bout\n",
    "            if \"Makuuchi\" in line:\n",
    "                division = \"Makuuchi\"\n",
    "            elif \"Juryo\" in line:\n",
    "                division = \"Juryo\"\n",
    "            elif \"Makushita\" in line:\n",
    "                division = \"Makushita\"\n",
    "            elif \"Sandanme\" in line:\n",
    "                division = \"Sandanme\"\n",
    "            elif \"Jonidan\" in line:\n",
    "                division = \"Jonidan\"\n",
    "            elif \"Jonokuchi\" in line:\n",
    "                division = \"Jonokuchi\"\n",
    "\n",
    "            #use the number of spaces in the line and the beginning of the rank codes to filter out the irrelevant lines                     \n",
    "            if \"    \" in line and \"changed from\" not in line and line.startswith(\"Bg\") == False and line.startswith(\"Sj\") == False and line.startswith(\"Mz\") == False:\n",
    "                line = line + \" \"\n",
    "\n",
    "                #remove extra spaces\n",
    "                processed_line = re.sub(' +', ' ', line)\n",
    "\n",
    "                #separates the columns \n",
    "                split = processed_line.split(\" \")\n",
    "\n",
    "                #adjust the splits if winning_technique merges with wrestler_2_rank\n",
    "                if len(split[3]) >= 16:\n",
    "                    split[6] = split[5]\n",
    "                    split[5] = split[4]\n",
    "                    split[4] = split[3][16:]\n",
    "                    split[3] = split[3][:16]\n",
    "                    split[2] = split[2]\n",
    "                    split[1] = split[1]\n",
    "                    split[0] = split[0]\n",
    "\n",
    "                #default column layout\n",
    "                wrestler_1_rank = split[0]\n",
    "                wrestler_1_name = split[1]\n",
    "                wrestler_1_record = split[2]\n",
    "                winning_technique = split[3]\n",
    "                wrestler_2_rank = split[4]\n",
    "                wrestler_2_name = split[5]\n",
    "                wrestler_2_record = split[6]\n",
    "\n",
    "                #apply the parsed data to the dataframe\n",
    "                df.loc[len(df.index)] = [tournament_date, tournament_day_no, division, winning_technique, wrestler_1_rank, \n",
    "                                        wrestler_1_name, wrestler_1_record, wrestler_2_rank, wrestler_2_name, wrestler_2_record]\n",
    "\n",
    "#parse the data for each decade\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/1950/\", tournament_1950)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/1960/\", tournament_1960)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/1970/\", tournament_1970)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/1980/\", tournament_1980)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/1990/\", tournament_1990)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/2000/\", tournament_2000)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/2010/\", tournament_2010)\n",
    "parse_tournament_data(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/torikumi/2020/\", tournament_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d6f1c",
   "metadata": {},
   "source": [
    "Parse in the name changes from the banzuke files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1da2e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_names_1950 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_1960 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_1970 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_1980 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_1990 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_2000 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_2010 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "changed_names_2020 = pd.DataFrame(columns=(\"rank\", \"old_name\", \"new_name\", \"date_changed\")) \n",
    "\n",
    "def parse_name_changes(path, df):\n",
    "\n",
    "    #set directory\n",
    "    name_changes_path = os.chdir(path)\n",
    "    #run through all files in directory\n",
    "    for files in os.listdir(name_changes_path):           \n",
    "            \n",
    "        file_name = files\n",
    "        files = open(file_name, \"r\")\n",
    "        lines = files.readlines()\n",
    "        files.close()\n",
    "\n",
    "        #get date of the name change\n",
    "        rank_date_string = file_name[0:4] + \"-\" + file_name[5:7]\n",
    "        rank_date = datetime.datetime.strptime(rank_date_string, \"%Y-%m\")\n",
    "\n",
    "        #get the sumo data\n",
    "        for line in lines:\n",
    "                                \n",
    "            if \"changed from\" in line:\n",
    "                \n",
    "                line = line + \" \"\n",
    "\n",
    "                #remove extra spaces\n",
    "                processed_line = re.sub(' +', ' ', line)\n",
    "\n",
    "                #separates the columns \n",
    "                split = processed_line.split(\" \")\n",
    "                \n",
    "                rank = split[0]\n",
    "                new_name = split[1]\n",
    "                old_name = split[4]\n",
    "\n",
    "                df.loc[len(df.index)] = [rank, old_name, new_name, rank_date]\n",
    "\n",
    "#parse the data for each decade\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1950/\",changed_names_1950)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1960/\",changed_names_1960)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1970/\",changed_names_1970)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1980/\",changed_names_1980)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/1990/\",changed_names_1990)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/2000/\",changed_names_2000)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/2010/\",changed_names_2010)\n",
    "parse_name_changes(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/banzuke/2020/\",changed_names_2020)\n",
    "\n",
    "#concat the name changes by decade into one dataframe\n",
    "changed_names = pd.concat([changed_names_1950, changed_names_1960, changed_names_1970, changed_names_1980, \n",
    "                    changed_names_1990, changed_names_2000, changed_names_2010, changed_names_2020], \n",
    "                    ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f30ae2",
   "metadata": {},
   "source": [
    "Cleaning Stage:\n",
    "Remove ranking data outside of the top two divisions prior to 1990 as there is only tournament data for the top two division data prior to 1988, and then 1988-1989 the lower divisions have many missing values. After 1990 all data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67fe2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeps only the rows for wrestlers in the top two divisions between 1950 and 1979\n",
    "ranking_1950 = ranking_1950[ranking_1950[\"division\"].isin([\"Makuuchi\", \"Juryo\"]) == True]\n",
    "ranking_1960 = ranking_1960[ranking_1960[\"division\"].isin([\"Makuuchi\", \"Juryo\"]) == True]\n",
    "ranking_1970 = ranking_1970[ranking_1970[\"division\"].isin([\"Makuuchi\", \"Juryo\"]) == True]\n",
    "ranking_1980 = ranking_1980[ranking_1980[\"division\"].isin([\"Makuuchi\", \"Juryo\"]) == True]\n",
    "\n",
    "#reset the index after removing the rows\n",
    "ranking_1950.reset_index(drop=True, inplace=True)\n",
    "ranking_1960.reset_index(drop=True, inplace=True)\n",
    "ranking_1970.reset_index(drop=True, inplace=True)\n",
    "ranking_1980.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768acdce",
   "metadata": {},
   "source": [
    "Append each decade of ranking and tournament dataframes back together and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04efc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending the ranking dataframes\n",
    "ranking_df = ranking_1950.append(ranking_1960).append(ranking_1970).append(ranking_1980)\n",
    "ranking_df = ranking_df.append(ranking_1990).append(ranking_2000).append(ranking_2010).append(ranking_2020)\n",
    "\n",
    "#appending the tournament dataframes\n",
    "tournament_df = tournament_1950.append(tournament_1960).append(tournament_1970).append(tournament_1980)\n",
    "tournament_df = tournament_df.append(tournament_1990).append(tournament_2000).append(tournament_2010).append(tournament_2020)\n",
    "\n",
    "#reset the indexes of the two dataframes\n",
    "ranking_df.reset_index(drop=True, inplace=True)\n",
    "tournament_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7897bee",
   "metadata": {},
   "source": [
    "Set NaNs for all cells without values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cc91bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dashes to NaN for ranking dateframes\n",
    "ranking_df = ranking_df.replace(\"-\", np.NaN)\n",
    "\n",
    "#convert dashes to NaN for tournament dateframes\n",
    "tournament_df = tournament_df.replace(\"-\", np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d676bb",
   "metadata": {},
   "source": [
    "Remove the hashtages from the ranking data that were indicating name changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c17255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete hashtags within the \"name\" column\n",
    "ranking_df[\"name\"] = ranking_df[\"name\"].str.replace(\"#\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e836ef1",
   "metadata": {},
   "source": [
    "Convert all date and time columns to just date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d9d7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df[\"dob\"] = pd.to_datetime(ranking_df[\"dob\"]).dt.normalize()\n",
    "ranking_df[\"rank_date\"] = pd.to_datetime(ranking_df[\"rank_date\"]).dt.normalize()\n",
    "tournament_df[\"date\"] = pd.to_datetime(tournament_df[\"date\"]).dt.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273046ad",
   "metadata": {},
   "source": [
    "Change the wrestler's age in days to years for the ranking dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32d8cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert age column to string\n",
    "ranking_df[\"age\"] = ranking_df[\"age\"].astype(\"string\")\n",
    "\n",
    "#remove the \"days\"\n",
    "ranking_df[\"age\"] = ranking_df[\"age\"].str.replace(\" days\",\"\")\n",
    "\n",
    "#convert to int\n",
    "ranking_df[\"age\"] = ranking_df[\"age\"].astype(\"int\")\n",
    "\n",
    "#set NaN ages to zero, then divide the years, then convert zero values back to NaN\n",
    "ranking_df[\"age\"] = ((ranking_df[\"age\"].fillna(0)) / 365.25).replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e47f4",
   "metadata": {},
   "source": [
    "Remove brackets, \"d\" and \"\\n\" from the wrestler records in all the tournament dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e654ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp/ipykernel_4964/2534270476.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  tournament_df[\"record_1\"] = tournament_df[\"record_1\"].str.replace(\"(\",\"\")\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp/ipykernel_4964/2534270476.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  tournament_df[\"record_2\"] = tournament_df[\"record_2\"].str.replace(\"(\",\"\")\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp/ipykernel_4964/2534270476.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  tournament_df[\"record_1\"] = tournament_df[\"record_1\"].str.replace(\")\",\"\")\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp/ipykernel_4964/2534270476.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  tournament_df[\"record_2\"] = tournament_df[\"record_2\"].str.replace(\")\",\"\")\n"
     ]
    }
   ],
   "source": [
    "#removing brackets, \"d\" and \"\\n\"\n",
    "tournament_df[\"record_1\"] = tournament_df[\"record_1\"].str.replace(\"(\",\"\")\n",
    "tournament_df[\"record_2\"] = tournament_df[\"record_2\"].str.replace(\"(\",\"\")\n",
    "tournament_df[\"record_1\"] = tournament_df[\"record_1\"].str.replace(\")\",\"\")\n",
    "tournament_df[\"record_2\"] = tournament_df[\"record_2\"].str.replace(\")\",\"\")\n",
    "tournament_df[\"record_1\"] = tournament_df[\"record_1\"].str.replace(\"d\",\"\")\n",
    "tournament_df[\"record_2\"] = tournament_df[\"record_2\"].str.replace(\"d\",\"\")\n",
    "tournament_df[\"record_2\"] = tournament_df[\"record_2\"].str.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb5dbb",
   "metadata": {},
   "source": [
    "Change the format of the wrestler's records so that all are win-loss-missed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "028223fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a second dash to both wrestler record columns\n",
    "def format_wrestler_records(column):\n",
    "    \n",
    "    for i, row in tournament_df.iterrows():\n",
    "        dashes = row[column].count(\"-\")\n",
    "        \n",
    "        if dashes == 1:\n",
    "            tournament_df.at[i, column] = tournament_df.at[i, column] + \"-0\"\n",
    "\n",
    "format_wrestler_records(\"record_1\")\n",
    "format_wrestler_records(\"record_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22289d95",
   "metadata": {},
   "source": [
    "Split the record columns into three columns - one for wins, one for losses and one for missed bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "838470e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split on dashes for each wrestler using their record column to create three new columns\n",
    "tournament_df[[\"wins_1\", \"losses_1\", \"missed_1\"]] = tournament_df.record_1.str.split(\"-\", expand=True)\n",
    "tournament_df[[\"wins_2\", \"losses_2\", \"missed_2\"]] = tournament_df.record_2.str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6daff5e",
   "metadata": {},
   "source": [
    "Remove the original record column now that the wins, losses, missed columns have been created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3967870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop \"record_1\" and \"record_2\" columns for each data frame\n",
    "tournament_df = tournament_df.drop(\"record_1\", axis=1)\n",
    "tournament_df = tournament_df.drop(\"record_2\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70050425",
   "metadata": {},
   "source": [
    "Remove hashtags, commas and \"\\n\" from the names in the changed names dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72545d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting the changed names to remove unnecessary characters\n",
    "changed_names[\"old_name\"] = changed_names[\"old_name\"].str.replace(\"#\",\"\")\n",
    "changed_names[\"new_name\"] = changed_names[\"new_name\"].str.replace(\"#\",\"\")\n",
    "changed_names[\"old_name\"] = changed_names[\"old_name\"].str.replace(\",\",\"\")\n",
    "changed_names[\"new_name\"] = changed_names[\"new_name\"].str.replace(\",\",\"\")\n",
    "changed_names[\"old_name\"] = changed_names[\"old_name\"].str.replace(\"\\n\",\"\")\n",
    "changed_names[\"new_name\"] = changed_names[\"new_name\"].str.replace(\"\\n\",\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e177f",
   "metadata": {},
   "source": [
    "Add the name changes to the rankings data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ea369ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find rows with name changes by using the name, rank and date of the change\n",
    "rows_with_name_changes = ranking_df[ranking_df.set_index(['name','rank_code', 'rank_date']).index.isin(changed_names.set_index(['new_name','rank', 'date_changed']).index)]\n",
    "    \n",
    "#convert the rows with name changes to an array of row numbers\n",
    "index_of_rows_with_name_changes = rows_with_name_changes.index.values\n",
    "\n",
    "#add a new column for name changes \n",
    "ranking_df.loc[index_of_rows_with_name_changes, \"other_name(s)\"] = \"yes\" #need to set this to the changed name as \"changed_names.old_name\" is setting the wrong name (index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b051ae1",
   "metadata": {},
   "source": [
    "Create unique identifiers on the ranking dataframe by using the birth place and the birth date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5de0debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df['wrestler_id'] = ranking_df.dob.astype(str) + '_' + ranking_df.birthplace.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e6937",
   "metadata": {},
   "source": [
    "Save the dataframes to Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f06ae77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the paths for the cleaned dataframes to be saved\n",
    "cleaned_data_path = os.chdir('C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/cleaned_datasets/')\n",
    "\n",
    "#save the cleaned dataframes as excel documents\n",
    "ranking_df.to_excel('cleaned_ranking.xlsx', sheet_name='sheet1', index=False)\n",
    "tournament_df.to_excel('cleaned_tournament.xlsx', sheet_name='sheet1', index=False)\n",
    "changed_names.to_excel('cleaned_changed_names.xlsx', sheet_name='sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015a6f5",
   "metadata": {},
   "source": [
    "*temp - load the most up-to-date version of the dataframes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "897006dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the cleaned ranking data\n",
    "ranking_df = pd.read_excel('C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/cleaned_datasets/cleaned_ranking.xlsx')\n",
    "\n",
    "#load the cleaned tournament data\n",
    "tournament_df = pd.read_excel(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/cleaned_datasets/cleaned_tournament.xlsx\")\n",
    "\n",
    "#load the cleaned name changes\n",
    "changed_names = pd.read_excel(\"C:/Users/Josh/Documents/Uni/Dissertation/Data/sumo/cleaned_datasets/cleaned_changed_names.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c311db66170448179af7a66efd3978b51641ebc0e0cc09282239370e62fe176"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
